"""
–°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∑–æ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π –ø–æ —á–∞—Å—Ç—è–º –∫—É–∑–æ–≤–∞
================================================================
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
1. –ü—Ä–æ—Å—Ç—É—é –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é 
2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å ML-–º–æ–¥–µ–ª—è–º–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∑–æ–Ω
3. –ê–Ω–∞–ª–∏–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π –ø–æ –∑–æ–Ω–∞–º
"""

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image, ImageDraw, ImageFont
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass
import json

@dataclass
class ZoneAnalysis:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –æ–¥–Ω–æ–π –∑–æ–Ω—ã"""
    zone_name: str
    damage_probability: float
    damage_class: str  # 'no_damage', 'minor_damage', 'major_damage'
    confidence: float
    integrity_score: float  # –ü—Ä–æ—Ü–µ–Ω—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ (100 - damage_probability)
    bbox: Tuple[int, int, int, int]  # x1, y1, x2, y2

@dataclass
class CarAnalysisReport:
    """–ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è"""
    overall_integrity: float
    overall_grade: str
    zones: List[ZoneAnalysis]
    total_zones: int
    damaged_zones: int
    original_image_path: str
    processed_image_path: Optional[str] = None

class CarZoneDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –∑–æ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª—è"""
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–æ–Ω—ã –∞–≤—Ç–æ–º–æ–±–∏–ª—è (–ø—Ä–æ—Å—Ç–∞—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è)
    ZONE_TEMPLATES = {
        'front': {'position': (0.2, 0.3, 0.8, 0.7), 'color': (255, 0, 0)},      # –ü–µ—Ä–µ–¥–Ω—è—è —á–∞—Å—Ç—å
        'rear': {'position': (0.2, 0.7, 0.8, 1.0), 'color': (0, 255, 0)},       # –ó–∞–¥–Ω—è—è —á–∞—Å—Ç—å  
        'roof': {'position': (0.25, 0.0, 0.75, 0.3), 'color': (0, 0, 255)},     # –ö—Ä—ã—à–∞
        'left_side': {'position': (0.0, 0.2, 0.4, 0.8), 'color': (255, 255, 0)}, # –õ–µ–≤–∞—è —Å—Ç–æ—Ä–æ–Ω–∞
        'right_side': {'position': (0.6, 0.2, 1.0, 0.8), 'color': (255, 0, 255)}, # –ü—Ä–∞–≤–∞—è —Å—Ç–æ—Ä–æ–Ω–∞
        'hood': {'position': (0.3, 0.15, 0.7, 0.45), 'color': (0, 255, 255)},   # –ö–∞–ø–æ—Ç
        'trunk': {'position': (0.3, 0.55, 0.7, 0.85), 'color': (128, 128, 128)} # –ë–∞–≥–∞–∂–Ω–∏–∫
    }
    
    def __init__(self, detection_method='geometric'):
        """
        Args:
            detection_method: 'geometric' –∏–ª–∏ 'ml' (–¥–ª—è –±—É–¥—É—â–∏—Ö ML-–¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤)
        """
        self.detection_method = detection_method
        
    def detect_zones(self, image: np.ndarray) -> Dict[str, Tuple[int, int, int, int]]:
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –∑–æ–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—è (numpy array)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å {zone_name: (x1, y1, x2, y2)}
        """
        if self.detection_method == 'geometric':
            return self._detect_zones_geometric(image)
        else:
            raise NotImplementedError(f"–ú–µ—Ç–æ–¥ {self.detection_method} –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")
    
    def _detect_zones_geometric(self, image: np.ndarray) -> Dict[str, Tuple[int, int, int, int]]:
        """–ü—Ä–æ—Å—Ç–∞—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è"""
        h, w = image.shape[:2]
        zones = {}
        
        for zone_name, zone_info in self.ZONE_TEMPLATES.items():
            x1_rel, y1_rel, x2_rel, y2_rel = zone_info['position']
            
            x1 = int(x1_rel * w)
            y1 = int(y1_rel * h)
            x2 = int(x2_rel * w)
            y2 = int(y2_rel * h)
            
            zones[zone_name] = (x1, y1, x2, y2)
            
        return zones
    
    def extract_zone_images(self, image: np.ndarray, zones: Dict[str, Tuple[int, int, int, int]]) -> Dict[str, np.ndarray]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–æ–Ω"""
        zone_images = {}
        
        for zone_name, (x1, y1, x2, y2) in zones.items():
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(image.shape[1], x2)
            y2 = min(image.shape[0], y2)
            
            if x2 > x1 and y2 > y1:
                zone_image = image[y1:y2, x1:x2]
                zone_images[zone_name] = zone_image
                
        return zone_images

class CarDamageAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ø–æ –∑–æ–Ω–∞–º"""
    
    def __init__(self, model_path: str, device: str = 'cpu'):
        """
        Args:
            model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        """
        self.device = device
        self.model = self._load_model(model_path)
        self.zone_detector = CarZoneDetector()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
        from torchvision import transforms
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
    def _load_model(self, model_path: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        try:
            from multiclass_damage_model import MulticlassDamageModel
            
            model = MulticlassDamageModel(num_classes=3)
            checkpoint = torch.load(model_path, map_location=self.device)
            
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
                
            model.eval()
            model.to(self.device)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
            return model
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return None
    
    def analyze_zone(self, zone_image: np.ndarray) -> Tuple[str, float, float]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–π –∑–æ–Ω–µ
        
        Returns:
            (damage_class, damage_probability, confidence)
        """
        if self.model is None:
            # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            damage_prob = np.random.uniform(0, 1)
            if damage_prob < 0.6:
                return 'no_damage', damage_prob, 0.8
            elif damage_prob < 0.8:
                return 'minor_damage', damage_prob, 0.7
            else:
                return 'major_damage', damage_prob, 0.9
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–∏
        if len(zone_image.shape) == 3 and zone_image.shape[2] == 3:
            # RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            input_tensor = self.transform(zone_image).unsqueeze(0).to(self.device)
        else:
            print("‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return 'no_damage', 0.0, 0.0
        
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = F.softmax(outputs, dim=1)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            class_probs = probabilities[0].cpu().numpy()
            predicted_class = np.argmax(class_probs)
            confidence = float(class_probs[predicted_class])
            
            # Mapping –∫–ª–∞—Å—Å–æ–≤
            class_names = ['no_damage', 'minor_damage', 'major_damage']
            damage_class = class_names[predicted_class]
            
            # –û–±—â–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è (minor + major)
            damage_probability = float(class_probs[1] + class_probs[2])
            
            return damage_class, damage_probability, confidence
    
    def analyze_car(self, image_path: str) -> CarAnalysisReport:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∞–≤—Ç–æ–º–æ–±–∏–ª—è
            
        Returns:
            –û—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –∑–æ–Ω—ã
        zones = self.zone_detector.detect_zones(image_rgb)
        zone_images = self.zone_detector.extract_zone_images(image_rgb, zones)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∑–æ–Ω—É
        zone_analyses = []
        total_damage_prob = 0
        damaged_zones = 0
        
        for zone_name, zone_image in zone_images.items():
            if zone_name not in zones:
                continue
                
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–æ–Ω—É
            damage_class, damage_prob, confidence = self.analyze_zone(zone_image)
            
            # –°–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑ –∑–æ–Ω—ã
            zone_analysis = ZoneAnalysis(
                zone_name=zone_name,
                damage_probability=damage_prob,
                damage_class=damage_class,
                confidence=confidence,
                integrity_score=100 - (damage_prob * 100),
                bbox=zones[zone_name]
            )
            
            zone_analyses.append(zone_analysis)
            total_damage_prob += damage_prob
            
            if damage_class != 'no_damage':
                damaged_zones += 1
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        avg_damage_prob = total_damage_prob / len(zone_analyses) if zone_analyses else 0
        overall_integrity = 100 - (avg_damage_prob * 100)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É
        if overall_integrity >= 90:
            overall_grade = "–û–¢–õ–ò–ß–ù–û–ï"
        elif overall_integrity >= 75:
            overall_grade = "–•–û–†–û–®–ï–ï"
        elif overall_integrity >= 60:
            overall_grade = "–£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û–ï"
        elif overall_integrity >= 40:
            overall_grade = "–ü–õ–û–•–û–ï"
        else:
            overall_grade = "–ö–†–ò–¢–ò–ß–ï–°–ö–û–ï"
        
        return CarAnalysisReport(
            overall_integrity=overall_integrity,
            overall_grade=overall_grade,
            zones=zone_analyses,
            total_zones=len(zone_analyses),
            damaged_zones=damaged_zones,
            original_image_path=image_path
        )

class CarReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞"""
    
    def __init__(self):
        # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        self.damage_colors = {
            'no_damage': (0, 255, 0),      # –ó–µ–ª—ë–Ω—ã–π
            'minor_damage': (255, 165, 0),  # –û—Ä–∞–Ω–∂–µ–≤—ã–π
            'major_damage': (255, 0, 0)     # –ö—Ä–∞—Å–Ω—ã–π
        }
    
    def create_visual_report(self, report: CarAnalysisReport, output_path: str) -> str:
        """
        –°–æ–∑–¥–∞—ë—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –∑–æ–Ω
        
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –æ—Ç—á—ë—Ç–∞
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = cv2.imread(report.original_image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
        annotated_image = image_rgb.copy()
        
        # –†–∏—Å—É–µ–º –∑–æ–Ω—ã –∏ –ø–æ–¥–ø–∏—Å–∏
        for zone in report.zones:
            x1, y1, x2, y2 = zone.bbox
            color = self.damage_colors[zone.damage_class]
            
            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –∑–æ–Ω—ã
            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 3)
            
            # –ü–æ–¥–ø–∏—Å—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–æ–Ω–µ
            label = f"{zone.zone_name}: {zone.integrity_score:.1f}%"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            
            # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            cv2.rectangle(annotated_image, 
                         (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), 
                         color, -1)
            
            # –¢–µ–∫—Å—Ç
            cv2.putText(annotated_image, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        annotated_bgr = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)
        cv2.imwrite(output_path, annotated_bgr)
        
        return output_path
    
    def generate_text_report(self, report: CarAnalysisReport) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç"""
        
        report_text = f"""
üöó –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–Å–¢ –ê–ù–ê–õ–ò–ó–ê –ê–í–¢–û–ú–û–ë–ò–õ–Ø
{'=' * 50}

üìä –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê:
‚Ä¢ –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å: {report.overall_integrity:.1f}%
‚Ä¢ –°–æ—Å—Ç–æ—è–Ω–∏–µ: {report.overall_grade}
‚Ä¢ –ü–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã—Ö –∑–æ–Ω: {report.damaged_zones}/{report.total_zones}

üîç –ê–ù–ê–õ–ò–ó –ü–û –ó–û–ù–ê–ú:
{'‚îÄ' * 30}
"""
        
        for zone in sorted(report.zones, key=lambda x: x.integrity_score):
            status_emoji = "‚úÖ" if zone.damage_class == 'no_damage' else ("‚ö†Ô∏è" if zone.damage_class == 'minor_damage' else "‚ùå")
            
            report_text += f"""
{status_emoji} {zone.zone_name.upper().replace('_', ' ')}:
   ‚Ä¢ –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å: {zone.integrity_score:.1f}%
   ‚Ä¢ –¢–∏–ø –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è: {zone.damage_class.replace('_', ' ').title()}
   ‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {zone.confidence:.1f}%
"""
        
        return report_text
    
    def save_json_report(self, report: CarAnalysisReport, output_path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á—ë—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ"""
        
        report_dict = {
            'overall_integrity': report.overall_integrity,
            'overall_grade': report.overall_grade,
            'total_zones': report.total_zones,
            'damaged_zones': report.damaged_zones,
            'original_image': report.original_image_path,
            'zones': [
                {
                    'name': zone.zone_name,
                    'integrity_score': zone.integrity_score,
                    'damage_class': zone.damage_class,
                    'damage_probability': zone.damage_probability,
                    'confidence': zone.confidence,
                    'bbox': zone.bbox
                }
                for zone in report.zones
            ]
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report_dict, f, ensure_ascii=False, indent=2)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_car_analysis(image_path: str, model_path: str = None):
    """
    –¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
    
    Args:
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∞–≤—Ç–æ–º–æ–±–∏–ª—è
        model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    print("üöó –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è...")
    
    # –°–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (—Å –º–æ–¥–µ–ª—å—é –∏–ª–∏ –±–µ–∑)
    if model_path:
        analyzer = CarDamageAnalyzer(model_path)
    else:
        print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º")
        analyzer = CarDamageAnalyzer("dummy_path")  # –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–≥–ª—É—à–∫—É
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–≤—Ç–æ–º–æ–±–∏–ª—å
    try:
        report = analyzer.analyze_car(image_path)
        
        # –°–æ–∑–¥–∞—ë–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á—ë—Ç–æ–≤
        report_generator = CarReportGenerator()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç
        text_report = report_generator.generate_text_report(report)
        print(text_report)
        
        # –°–æ–∑–¥–∞—ë–º –≤–∏–∑—É–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç
        output_image = "test_car_analysis_result.jpg"
        visual_report_path = report_generator.create_visual_report(report, output_image)
        print(f"\nüì∏ –í–∏–∑—É–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {visual_report_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –æ—Ç—á—ë—Ç
        json_output = "test_car_analysis_result.json"
        report_generator.save_json_report(report, json_output)
        print(f"üìÑ JSON –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {json_output}")
        
        return report
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return None

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print("üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∑–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è")
    
    # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–∑–∞–≥–ª—É—à–∫—É)
    test_image = np.ones((600, 800, 3), dtype=np.uint8) * 128
    cv2.imwrite("test_car.jpg", test_image)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
    test_car_analysis("test_car.jpg")