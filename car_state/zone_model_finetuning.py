"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏ –ø–æ–¥ –∑–∞–¥–∞—á—É –∑–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
=====================================================================
–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
1. Fine-tuning —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
2. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–ª–æ—ë–≤ –¥–ª—è –∑–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞  
3. –û–±—É—á–µ–Ω–∏–µ —Å —É—á—ë—Ç–æ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π —Ä–∞–∑–Ω—ã—Ö –∑–æ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª—è
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import cv2
from pathlib import Path
import json
import logging
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import matplotlib.pyplot as plt

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ZoneTrainingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∑–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    base_model_path: str
    zones_data_path: str
    output_model_path: str
    epochs: int = 15
    learning_rate: float = 1e-4
    batch_size: int = 8
    freeze_backbone: bool = True  # –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å backbone –Ω–∞ –ø–µ—Ä–≤—ã—Ö —ç–ø–æ—Ö–∞—Ö
    zone_weights: Dict[str, float] = None  # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–æ–Ω

class ZoneSpecificModel(nn.Module):
    """–ú–æ–¥–µ–ª—å —Å —É—á—ë—Ç–æ–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ –∑–æ–Ω"""
    
    def __init__(self, base_model, num_zones=7, num_classes=3):
        super(ZoneSpecificModel, self).__init__()
        
        self.base_model = base_model
        self.num_zones = num_zones
        self.num_classes = num_classes
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–µ—Ä–µ–∑ dummy forward pass
        dummy_input = torch.randn(1, 3, 224, 224)
        try:
            with torch.no_grad():
                dummy_features = base_model.backbone(dummy_input)
                # –ü—Ä–∏–º–µ–Ω—è–µ–º GlobalAveragePooling –µ—Å–ª–∏ –µ—Å—Ç—å
                if hasattr(base_model, 'avgpool'):
                    dummy_features = base_model.avgpool(dummy_features)
                # Flatten
                dummy_features = dummy_features.view(dummy_features.size(0), -1)
                base_features = dummy_features.size(1)
                logger.info(f"–û–ø—Ä–µ–¥–µ–ª—ë–Ω —Ä–∞–∑–º–µ—Ä features: {base_features}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä —á–µ—Ä–µ–∑ forward pass: {e}")
            base_features = 2048  # Fallback –¥–ª—è ResNet50
        
        # –ó–∞–º–µ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ identity
        # –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º backbone + avgpool
        self.backbone = base_model.backbone
        if hasattr(base_model, 'avgpool'):
            self.avgpool = base_model.avgpool
        else:
            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–æ–Ω–∞–ª—å–Ω–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Å–ª–æ–∏
        self.zone_embedding = nn.Embedding(num_zones, 64)
        
        # –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        self.combined_classifier = nn.Sequential(
            nn.Linear(base_features + 64, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )
        
        # Mapping –∑–æ–Ω –∫ ID
        self.zone_to_id = {
            'front': 0, 'rear': 1, 'roof': 2, 'left_side': 3, 
            'right_side': 4, 'hood': 5, 'trunk': 6
        }
    
    def forward(self, x, zone_ids):
        """
        Forward pass —Å —É—á—ë—Ç–æ–º –∑–æ–Ω—ã
        
        Args:
            x: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (batch_size, 3, 224, 224)
            zone_ids: ID –∑–æ–Ω (batch_size,)
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º features –∏–∑ backbone
        features = self.backbone(x)
        features = self.avgpool(features)
        features = features.view(features.size(0), -1)  # Flatten
        
        # –ü–æ–ª—É—á–∞–µ–º zone embeddings
        zone_emb = self.zone_embedding(zone_ids)  # (batch_size, 64)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º features
        combined = torch.cat([features, zone_emb], dim=1)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        output = self.combined_classifier(combined)
        
        return output

class ZoneDataset(Dataset):
    """Dataset –¥–ª—è –∑–æ–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, zones_data_path: str, transform=None):
        """
        Args:
            zones_data_path: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –∑–æ–Ω
            transform: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        """
        self.transform = transform
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–æ–Ω
        with open(zones_data_path, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        self.samples = []
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—ç–º–ø–ª—ã
        for item in self.data:
            if 'zones' in item:
                base_image_path = item['image_path']
                
                for zone_info in item['zones']:
                    sample = {
                        'image_path': base_image_path,
                        'zone_name': zone_info['name'],
                        'zone_bbox': zone_info['bbox'],
                        'damage_class': zone_info.get('damage_class', 0),
                        'zone_id': self._zone_name_to_id(zone_info['name'])
                    }
                    self.samples.append(sample)
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.samples)} –∑–æ–Ω–∞–ª—å–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤")
    
    def _zone_name_to_id(self, zone_name: str) -> int:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–º—è –∑–æ–Ω—ã –≤ ID"""
        zone_mapping = {
            'front': 0, 'rear': 1, 'roof': 2, 'left_side': 3, 
            'right_side': 4, 'hood': 5, 'trunk': 6
        }
        return zone_mapping.get(zone_name, 0)
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = cv2.imread(sample['image_path'])
        if image is None:
            # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —Å–æ–∑–¥–∞—ë–º –∑–∞–≥–ª—É—à–∫—É
            image = np.ones((224, 224, 3), dtype=np.uint8) * 128
        else:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–æ–Ω—É –ø–æ bbox
        x1, y1, x2, y2 = sample['zone_bbox']
        zone_image = image[y1:y2, x1:x2]
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∑–æ–Ω–∞ –Ω–µ –ø—É—Å—Ç–∞—è
        if zone_image.size == 0:
            zone_image = np.ones((64, 64, 3), dtype=np.uint8) * 128
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        if self.transform:
            try:
                from PIL import Image
                zone_pil = Image.fromarray(zone_image)
                zone_image = self.transform(zone_pil)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
                # Fallback: –ø—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                zone_image = cv2.resize(zone_image, (224, 224))
                zone_image = torch.from_numpy(zone_image.transpose(2, 0, 1)).float() / 255.0
        
        return zone_image, torch.tensor(sample['zone_id']), torch.tensor(sample['damage_class'])

def create_zone_training_data(base_images_dir: str, output_json: str):
    """
    –°–æ–∑–¥–∞—ë—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    
    Args:
        base_images_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
        output_json: –§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    """
    from car_zone_detector import CarZoneDetector
    
    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    
    detector = CarZoneDetector()
    training_data = []
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    image_paths = list(Path(base_images_dir).glob("*.jpg")) + list(Path(base_images_dir).glob("*.png"))
    
    for img_path in image_paths[:20]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –¥–µ–º–æ
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = cv2.imread(str(img_path))
            if image is None:
                continue
                
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –∑–æ–Ω—ã
            zones = detector.detect_zones(image_rgb)
            
            # –°–æ–∑–¥–∞—ë–º —Å–ª—É—á–∞–π–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è –∑–æ–Ω (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–∞ —Ä–∞–∑–º–µ—Ç–∫–∞)
            zones_info = []
            for zone_name, bbox in zones.items():
                # –°–ª—É—á–∞–π–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è (–¥–ª—è –¥–µ–º–æ)
                damage_class = np.random.choice([0, 1, 2], p=[0.6, 0.3, 0.1])
                
                zones_info.append({
                    'name': zone_name,
                    'bbox': list(bbox),
                    'damage_class': int(damage_class)
                })
            
            training_data.append({
                'image_path': str(img_path),
                'zones': zones_info
            })
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path}: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(training_data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"–°–æ–∑–¥–∞–Ω–æ {len(training_data)} –∑–∞–ø–∏—Å–µ–π –≤ {output_json}")
    return output_json

def finetune_model_for_zones(config: ZoneTrainingConfig):
    """
    –î–æ–æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –∑–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    
    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
    """
    logger.info("–ù–∞—á–∞–ª–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {config.base_model_path}")
    
    try:
        from multiclass_damage_model import MulticlassDamageModel
        base_model = MulticlassDamageModel(num_classes=3)
        
        checkpoint = torch.load(config.base_model_path, map_location=device)
        if 'model_state_dict' in checkpoint:
            base_model.load_state_dict(checkpoint['model_state_dict'])
        else:
            base_model.load_state_dict(checkpoint)
            
        logger.info("‚úÖ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None
    
    # 2. –°–æ–∑–¥–∞—ë–º –∑–æ–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    zone_model = ZoneSpecificModel(base_model, num_zones=7, num_classes=3)
    zone_model.to(device)
    
    # –ó–∞–º–æ—Ä–æ–∑–∫–∞ backbone –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    if config.freeze_backbone:
        logger.info("üßä –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º backbone")
        for param in zone_model.backbone.parameters():
            param.requires_grad = False
    
    # 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    logger.info("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    # –°–æ–∑–¥–∞—ë–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if not Path(config.zones_data_path).exists():
        logger.info("–°–æ–∑–¥–∞—ë–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ
        demo_data = [
            {
                'image_path': 'demo_car.jpg',
                'zones': [
                    {'name': 'front', 'bbox': [160, 180, 640, 420], 'damage_class': 1},
                    {'name': 'rear', 'bbox': [160, 420, 640, 600], 'damage_class': 0},
                    {'name': 'roof', 'bbox': [200, 0, 600, 180], 'damage_class': 0},
                    {'name': 'hood', 'bbox': [240, 90, 560, 270], 'damage_class': 2},
                ]
            }
        ]
        
        with open(config.zones_data_path, 'w', encoding='utf-8') as f:
            json.dump(demo_data, f, ensure_ascii=False, indent=2)
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    from torchvision import transforms
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # –°–æ–∑–¥–∞—ë–º dataset
    try:
        dataset = ZoneDataset(config.zones_data_path, transform=transform)
        
        # Split –Ω–∞ train/val
        train_size = int(0.8 * len(dataset))
        val_size = len(dataset) - train_size
        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
        
        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)
        
        logger.info(f"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è dataset: {e}")
        return None
    
    # 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è
    criterion = nn.CrossEntropyLoss()
    
    # –†–∞–∑–Ω—ã–µ learning rates –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π –º–æ–¥–µ–ª–∏
    params_to_update = []
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ–≤—ã—Ö —Å–ª–æ—ë–≤
    for param in zone_model.zone_embedding.parameters():
        params_to_update.append({'params': param, 'lr': config.learning_rate})
    
    for param in zone_model.combined_classifier.parameters():
        params_to_update.append({'params': param, 'lr': config.learning_rate})
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω–µ –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã)
    if not config.freeze_backbone:
        for param in zone_model.backbone.parameters():
            params_to_update.append({'params': param, 'lr': config.learning_rate * 0.1})
    
    optimizer = torch.optim.AdamW(params_to_update, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)
    
    # 6. –û–±—É—á–µ–Ω–∏–µ
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –∑–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    
    best_val_loss = float('inf')
    train_losses = []
    val_losses = []
    
    for epoch in range(config.epochs):
        # Training
        zone_model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (images, zone_ids, labels) in enumerate(train_loader):
            images = images.to(device)
            zone_ids = zone_ids.to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad()
            outputs = zone_model(images, zone_ids)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()
            
            if batch_idx % 5 == 0:
                logger.info(f'Epoch {epoch+1}/{config.epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}')
        
        # Validation
        zone_model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, zone_ids, labels in val_loader:
                images = images.to(device)
                zone_ids = zone_ids.to(device)
                labels = labels.to(device)
                
                outputs = zone_model(images, zone_ids)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()
        
        # –ú–µ—Ç—Ä–∏–∫–∏ —ç–ø–æ—Ö–∏
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_acc = 100 * train_correct / train_total if train_total > 0 else 0
        val_acc = 100 * val_correct / val_total if val_total > 0 else 0
        
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        
        logger.info(f'Epoch {epoch+1}/{config.epochs}:')
        logger.info(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        logger.info(f'  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': zone_model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_loss': best_val_loss,
                'train_losses': train_losses,
                'val_losses': val_losses,
                'config': config.__dict__
            }, config.output_model_path)
            logger.info(f'üíæ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config.output_model_path}')
        
        scheduler.step()
        
        # –†–∞–∑–º–æ—Ä–æ–∑–∫–∞ backbone –Ω–∞ –ø–æ–ª–æ–≤–∏–Ω–µ –æ–±—É—á–µ–Ω–∏—è
        if config.freeze_backbone and epoch == config.epochs // 2:
            logger.info("üîì –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º backbone")
            for param in zone_model.backbone.parameters():
                param.requires_grad = True
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
            params_to_update = []
            for param in zone_model.parameters():
                if param.requires_grad:
                    params_to_update.append({'params': param, 'lr': config.learning_rate * 0.1})
            
            optimizer = torch.optim.AdamW(params_to_update, weight_decay=1e-4)
    
    logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    return config.output_model_path

def test_zone_model():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = ZoneTrainingConfig(
        base_model_path="training_results/best_model.pth",
        zones_data_path="zone_training_data.json",
        output_model_path="training_results/zone_specific_model.pth",
        epochs=5,  # –ú–∞–ª–æ —ç–ø–æ—Ö –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
        learning_rate=1e-4,
        batch_size=4
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–æ–æ–±—É—á–µ–Ω–∏–µ
    result = finetune_model_for_zones(config)
    
    if result:
        logger.info(f"‚úÖ –ó–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {result}")
        return True
    else:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –∑–æ–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å")
        return False

if __name__ == "__main__":
    print("üîß –î–û–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø –ó–û–ù–ê–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 50)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
    success = test_zone_model()
    
    if success:
        print("\nüéâ –î–æ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        print("üìÅ –§–∞–π–ª—ã:")
        print("   ‚Ä¢ zone_training_data.json - –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        print("   ‚Ä¢ training_results/zone_specific_model.pth - –¥–æ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
    else:
        print("\n‚ùå –î–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å")