# CarCondition/inference.py
from __future__ import annotations
from typing import Dict, Optional, Tuple, List
import io, os
from pathlib import Path
from functools import lru_cache

import numpy as np
from PIL import Image, ImageOps, ImageFilter, ImageStat

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as T
from torchvision import models
from dotenv import load_dotenv

# –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏–∑ —Ç–≤–æ–µ–≥–æ —Ñ–∞–π–ª–∞
from multiclass_damage_model import MulticlassDamageModel

load_dotenv()

MODEL_PATH = os.getenv("MODEL_PATH", "models/model.pth")
DEVICE     = os.getenv("DEVICE", "cpu")

# === –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–æ–≤–Ω–æ –∫–∞–∫ –≤ —Ç–≤–æ—ë–º —Ç–µ—Å—Ç–µ ===
_tf = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
])

# === –í–∞–ª–∏–¥–∞—Ü–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è ===
# Load a pre-trained model for vehicle detection (e.g., ResNet)
vehicle_detection_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
vehicle_detection_model.eval()

# Define a transformation pipeline for the input image
vehicle_transform = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def is_vehicle(image: Image.Image) -> bool:
    """Check if the image contains a vehicle."""
    # Apply transformations
    input_tensor = vehicle_transform(image).unsqueeze(0)

    # Perform inference
    with torch.no_grad():
        outputs = vehicle_detection_model(input_tensor)
        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)

    # Define vehicle-related classes (example: ImageNet class IDs for vehicles)
    vehicle_classes = list(range(817, 829))  # Example range for vehicle classes in ImageNet

    # Check if the top prediction corresponds to a vehicle
    top_class = torch.argmax(probabilities).item()
    if top_class in vehicle_classes:
        return True
    return False

def analyze_dirt_level(image: Image.Image) -> Tuple[float, Dict[str, float], str, str]:
    """
    –ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–Ω–æ—Å—Ç–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (dirt_prob [0..1], –º–µ—Ç—Ä–∏–∫–∏, —Å—Ç–∞—Ç—É—Å, —ç–º–æ–¥–∑–∏).
    """
    img_array = np.array(image)
    
    # –¶–≤–µ—Ç–æ–≤–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
    unique_colors_r = len(np.unique(img_array[:,:,0]))
    unique_colors_g = len(np.unique(img_array[:,:,1])) 
    unique_colors_b = len(np.unique(img_array[:,:,2]))
    color_diversity = (unique_colors_r + unique_colors_g + unique_colors_b) / 3
    
    # –ö–æ–Ω—Ç—Ä–∞—Å—Ç
    gray = image.convert('L')
    contrast = ImageStat.Stat(gray).stddev[0]
    
    # –ù–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å
    hsv = image.convert('HSV')
    hsv_array = np.array(hsv)
    saturation = float(np.mean(hsv_array[:,:,1]))
    
    # –ö–æ—Ä–∏—á–Ω–µ–≤—ã–µ –æ—Ç—Ç–µ–Ω–∫–∏
    brown_mask = (
        (img_array[:,:,0] > img_array[:,:,2]) &
        (img_array[:,:,1] > img_array[:,:,2]) &
        (img_array[:,:,0] < 150) &
        (img_array[:,:,1] < 120)
    )
    brown_ratio = float(np.sum(brown_mask)) / (img_array.shape[0] * img_array.shape[1])
    
    # –ß–µ—Ç–∫–æ—Å—Ç—å –∫—Ä–∞–µ–≤
    edge_image = gray.filter(ImageFilter.FIND_EDGES)
    edge_intensity = float(np.mean(np.array(edge_image)))
    
    # –Ø—Ä–∫–æ—Å—Ç—å
    brightness = float(np.mean(img_array))
    
    # –ü–æ–¥—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –≥—Ä—è–∑–∏
    dirt_score = 0.0
    
    if color_diversity < 80:
        dirt_score += 2
    elif color_diversity < 120:
        dirt_score += 1
    
    if contrast < 25:
        dirt_score += 2
    elif contrast < 40:
        dirt_score += 1
    
    if saturation < 60:
        dirt_score += 1.5
    elif saturation < 100:
        dirt_score += 0.5
    
    if brown_ratio > 0.15:
        dirt_score += 2
    elif brown_ratio > 0.08:
        dirt_score += 1
    
    if edge_intensity < 15:
        dirt_score += 1.5
    elif edge_intensity < 25:
        dirt_score += 0.5
    
    if brightness < 90:
        dirt_score += 1
    elif brightness < 110:
        dirt_score += 0.5
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è
    if dirt_score >= 6:
        status = "–æ—á–µ–Ω—å –≥—Ä—è–∑–Ω–∞—è"
        emoji = "üü§"
    elif dirt_score >= 4:
        status = "–≥—Ä—è–∑–Ω–∞—è"
        emoji = "üü´"
    elif dirt_score >= 2:
        status = "—Å–ª–µ–≥–∫–∞ –≥—Ä—è–∑–Ω–∞—è"
        emoji = "üü®"
    elif dirt_score >= 1:
        status = "–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å—Ç–∞—è"
        emoji = "üü©"
    else:
        status = "–æ—á–µ–Ω—å —á–∏—Å—Ç–∞—è"
        emoji = "‚ú®"
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0..1] (–º–∞–∫—Å–∏–º—É–º –ø–æ —à–∫–∞–ª–µ ‚âà 10)
    dirt_prob = float(np.clip(dirt_score / 10.0, 0.0, 1.0))

    metrics = {
        'color_diversity': float(color_diversity),
        'contrast': float(contrast),
        'saturation': float(saturation),
        'brown_ratio': float(brown_ratio),
        'edge_intensity': float(edge_intensity),
        'brightness': float(brightness),
        'dirt_score': float(dirt_score)
    }
    
    return dirt_prob, metrics, status, emoji

def determine_repairability(predicted_class: str, confidence: float, major_damage_prob: float) -> Tuple[str, Tuple[str, ...], str]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å –∞–≤—Ç–æ–º–æ–±–∏–ª—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Å–µ—Ä–≤–∏—Å–µ —Ç–∞–∫—Å–∏
    –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –ø–µ—Ä–µ–≤–æ–∑–æ–∫
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - repairability_status: "taxi_ready", "conditional_taxi", "repair_required", "taxi_banned"
    - repairability_message: –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —Ç–∞–∫—Å–æ–ø–∞—Ä–∫–∞
    - economic_assessment: –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    
    # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ —Ç–∞–∫—Å–∏ (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç!)
    TAXI_BAN_THRESHOLD = 75.0       # > 75% —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π = –ó–ê–ü–†–ï–¢ –Ω–∞ —Ä–∞–±–æ—Ç—É –≤ —Ç–∞–∫—Å–∏
    REPAIR_REQUIRED_THRESHOLD = 50.0 # 50-75% = –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ô —Ä–µ–º–æ–Ω—Ç –ø–µ—Ä–µ–¥ –¥–æ–ø—É—Å–∫–æ–º
    CONDITIONAL_THRESHOLD = 25.0     # 25-50% = —É—Å–ª–æ–≤–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
    MINOR_DAMAGE_TAXI_LIMIT = 40.0   # –¥–∞–∂–µ –º–µ–ª–∫–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –∏–º–∏–¥–∂–∞
    
    if predicted_class == 'major_damage':
        if confidence > 0.8 and major_damage_prob > TAXI_BAN_THRESHOLD:
            return "taxi_banned", (
                "üö´ –ê–í–¢–û–ú–û–ë–ò–õ–¨ –ó–ê–ü–†–ï–©–ï–ù –î–õ–Ø –†–ê–ë–û–¢–´ –í –¢–ê–ö–°–ò!",
                f"üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {major_damage_prob:.1f}%",
                f"üö® –ü—Ä–µ–≤—ã—à–µ–Ω –ø—Ä–µ–¥–µ–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ ({TAXI_BAN_THRESHOLD}%)",
                "‚ö†Ô∏è –†–ò–°–ö–ò: –£–≥—Ä–æ–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –∏ –≤–æ–¥–∏—Ç–µ–ª—è",
                "üìâ –†–ï–ü–£–¢–ê–¶–ò–Ø: –°–µ—Ä—å–µ–∑–Ω—ã–π —É—â–µ—Ä–± –∏–º–∏–¥–∂—É —Ç–∞–∫—Å–æ–ø–∞—Ä–∫–∞",
                "‚öñÔ∏è –ü–†–ê–í–û: –ù–∞—Ä—É—à–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–≤–æ–∑–∫–∞–º",
                "üéØ –†–ï–®–ï–ù–ò–ï: –ò—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –ø–∞—Ä–∫–∞, –ø—Ä–æ–¥–∞—Ç—å –∏–ª–∏ —É—Ç–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"
            ), "safety_violation"
            
        elif confidence > 0.6 or major_damage_prob > REPAIR_REQUIRED_THRESHOLD:
            return "repair_required", (
                "üîß –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ô –†–ï–ú–û–ù–¢ –ü–ï–†–ï–î –î–û–ü–£–°–ö–û–ú –ö –†–ê–ë–û–¢–ï",
                f"üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {major_damage_prob:.1f}%",
                f"‚öñÔ∏è –ü—Ä–µ–≤—ã—à–µ–Ω –ø–æ—Ä–æ–≥ –¥–æ–ø—É—Å–∫–∞ –∫ –ø–µ—Ä–µ–≤–æ–∑–∫–∞–º ({REPAIR_REQUIRED_THRESHOLD}%)",
                "üö´ –°–¢–ê–¢–£–°: –í–†–ï–ú–ï–ù–ù–û –ò–°–ö–õ–Æ–ß–ï–ù –∏–∑ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏",
                "üîß –¢–†–ï–ë–û–í–ê–ù–ò–Ø: –ö–∞–ø–∏—Ç–∞–ª—å–Ω—ã–π —Ä–µ–º–æ–Ω—Ç + —Ç–µ—Ö–æ—Å–º–æ—Ç—Ä",
                "üí∞ –û–∂–∏–¥–∞–µ–º—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã: 150-500 —Ç—ã—Å. —Ä—É–±.",
                "üìã –û–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ—Å–ª–µ —Ä–µ–º–æ–Ω—Ç–∞",
                "‚è±Ô∏è –í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è: 2-4 –Ω–µ–¥–µ–ª–∏"
            ), "mandatory_repair"
            
        elif major_damage_prob > CONDITIONAL_THRESHOLD:
            return "conditional_taxi", (
                "‚ö†Ô∏è –£–°–õ–û–í–ù–û –î–û–ü–£–°–¢–ò–ú –° –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø–ú–ò",
                f"üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {major_damage_prob:.1f}%",
                f"üî∂ –í –ø–æ–≥—Ä–∞–Ω–∏—á–Ω–æ–π –∑–æ–Ω–µ ({CONDITIONAL_THRESHOLD}-{REPAIR_REQUIRED_THRESHOLD}%)",
                "üöó –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø: –¢–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏–≥–æ—Ä–æ–¥—Å–∫–∏–µ –ø–æ–µ–∑–¥–∫–∏",
                "üö´ –ó–ê–ü–†–ï–¢: –ú–µ–∂–¥—É–≥–æ—Ä–æ–¥–Ω–∏–µ —Ä–µ–π—Å—ã –∏ VIP-–∫–ª–∏–µ–Ω—Ç—ã",
                "üîç –ö–û–ù–¢–†–û–õ–¨: –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–æ—Å–º–æ—Ç—Ä—ã",
                "üíº –°–¢–†–ê–•–û–í–ê–ù–ò–ï: –ü–æ–≤—ã—à–µ–Ω–Ω—ã–µ —Ç–∞—Ä–∏—Ñ—ã",
                "‚è∞ –ü–õ–ê–ù: –ü–ª–∞–Ω–æ–≤—ã–π —Ä–µ–º–æ–Ω—Ç –≤ —Ç–µ—á–µ–Ω–∏–µ –º–µ—Å—è—Ü–∞"
            ), "restricted_operation"
        else:
            return "conditional_taxi", (
                "üîß –ö–û–°–ú–ï–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ú–û–ù–¢ –†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù",
                f"üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {major_damage_prob:.1f}%",
                "‚úÖ –î–æ–ø—É—Å—Ç–∏–º–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ç–∞–∫—Å–∏",
                "üé® –ò–ú–ò–î–ñ: –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ —É—Å—Ç—Ä–∞–Ω–∏—Ç—å –≤–∏–¥–∏–º—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã",
                "üí∞ –ó–∞—Ç—Ä–∞—Ç—ã: 50-150 —Ç—ã—Å. —Ä—É–±. –Ω–∞ –∫–æ—Å–º–µ—Ç–∏–∫—É",
                "üèÜ –†–ï–ô–¢–ò–ù–ì: –ü–æ–º–æ–∂–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –≤—ã—Å–æ–∫–∏–µ –æ—Ü–µ–Ω–∫–∏"
            ), "cosmetic_repair"
    
    elif predicted_class == 'minor_damage':
        minor_damage_prob = 100 - major_damage_prob  # –ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        if confidence > 0.6 and minor_damage_prob > MINOR_DAMAGE_TAXI_LIMIT:
            return "conditional_taxi", (
                "üîß –ö–û–°–ú–ï–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ú–û–ù–¢ –ñ–ï–õ–ê–¢–ï–õ–ï–ù –î–õ–Ø –¢–ê–ö–°–ò",
                f"üé® –ó–∞–º–µ—Ç–Ω—ã–µ –∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ—Ñ–µ–∫—Ç—ã: {minor_damage_prob:.1f}%",
                "‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: –ù–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è",
                "üì± –ò–ú–ò–î–ñ: –ú–æ–∂–µ—Ç —Å–Ω–∏–∂–∞—Ç—å —Ä–µ–π—Ç–∏–Ω–≥ –∏ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤",
                "üí∞ –ó–∞—Ç—Ä–∞—Ç—ã –Ω–∞ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ: 30-100 —Ç—ã—Å. —Ä—É–±.",
                "üì± –û–¢–ó–´–í–´: –í–æ–∑–º–æ–∂–Ω—ã –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ –≤–Ω–µ—à–Ω–µ–º –≤–∏–¥–µ",
                "üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ü–ª–∞–Ω–æ–≤—ã–π –∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–º–æ–Ω—Ç"
            ), "image_improvement"
        else:
            return "taxi_ready", (
                "‚úÖ –ü–†–ò–ì–û–î–ï–ù –î–õ–Ø –†–ê–ë–û–¢–´ –í –¢–ê–ö–°–ò",
                "üîß –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ—Ñ–µ–∫—Ç—ã",
                "üöó –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–∏–≥–æ–¥–µ–Ω –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø–µ—Ä–µ–≤–æ–∑–æ–∫",
                "üí∞ –ó–∞—Ç—Ä–∞—Ç—ã: 10-50 —Ç—ã—Å. —Ä—É–±. –Ω–∞ –º–µ–ª–∫–∏–π —Ä–µ–º–æ–Ω—Ç",
                "‚è±Ô∏è –í—Ä–µ–º—è —Ä–µ–º–æ–Ω—Ç–∞: 1-3 –¥–Ω—è",
                "üèÜ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ö–æ—Ä–æ—à–µ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ —Å–µ—Ä–≤–∏—Å–∞"
            ), "minor_maintenance"
    
    else:  # no_damage
        return "taxi_ready", (
            "üèÜ –ò–î–ï–ê–õ–ï–ù –î–õ–Ø –ü–†–ï–ú–ò–£–ú –¢–ê–ö–°–ò-–°–ï–†–í–ò–°–ê",
            "‚ú® –ê–≤—Ç–æ–º–æ–±–∏–ª—å –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏",
            "üöó –ö–õ–ê–°–°: –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è VIP –∏ –±–∏–∑–Ω–µ—Å-–∫–ª–∏–µ–Ω—Ç–æ–≤",
            "üìà –†–ï–ô–¢–ò–ù–ì: –û–±–µ—Å–ø–µ—á–∏—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤",
            "üíé –¢–ê–†–ò–§–´: –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã –≤ –ø—Ä–µ–º–∏—É–º-—Å–µ–≥–º–µ–Ω—Ç–µ",
            "üéØ –°–¢–ê–¢–£–°: –≠—Ç–∞–ª–æ–Ω –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–∞–∫—Å–æ–ø–∞—Ä–∫–∞"
        ), "premium_ready"

def generate_expert_recommendations(predicted_class: str, confidence: float, probabilities: np.ndarray, 
                                  dirt_status: str, dirt_score: float, dirt_metrics: Dict[str, float]) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
    recommendations = []
    
    no_damage_prob = probabilities[0] * 100
    minor_damage_prob = probabilities[1] * 100
    major_damage_prob = probabilities[2] * 100
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫—É —Ä–µ–º–æ–Ω—Ç–æ–ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏
    repairability_status, repairability_msgs, economic_status = determine_repairability(
        predicted_class, confidence, major_damage_prob
    )
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º
    if predicted_class == 'major_damage':
        if confidence > 0.8:
            recommendations.append("üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è! –ê–≤—Ç–æ–º–æ–±–∏–ª—å –ù–ï –ü–†–ò–ì–û–î–ï–ù –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ç–∞–∫—Å–∏ –±–µ–∑ –∫–∞–ø–∏—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–º–æ–Ω—Ç–∞.")
            recommendations.append("‚öñÔ∏è –ù–∞—Ä—É—à–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø–µ—Ä–µ–≤–æ–∑–æ–∫.")
        elif confidence > 0.6:
            recommendations.append("‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –Ω–∞ —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è. –¢—Ä–µ–±—É–µ—Ç—Å—è –°–†–û–ß–ù–ê–Ø –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞!")
    elif predicted_class == 'minor_damage':
        if confidence > 0.7:
            recommendations.append("üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º–µ–ª–∫–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è (—Ü–∞—Ä–∞–ø–∏–Ω—ã, –ø–æ—Ç–µ—Ä—Ç–æ—Å—Ç–∏). –ö–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–º–æ–Ω—Ç –∂–µ–ª–∞—Ç–µ–ª–µ–Ω.")
            recommendations.append("üí∞ –û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã: 30-100 —Ç—ã—Å. —Ä—É–±.")
    else:  # no_damage
        if confidence > 0.85:
            recommendations.append("‚ú® –û—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ! –ê–≤—Ç–æ–º–æ–±–∏–ª—å –∏–¥–µ–∞–ª–µ–Ω –¥–ª—è –ø—Ä–µ–º–∏—É–º —Ç–∞–∫—Å–∏-—Å–µ—Ä–≤–∏—Å–∞.")
            recommendations.append("üèÜ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è VIP –∏ –±–∏–∑–Ω–µ—Å-–∫–ª–∏–µ–Ω—Ç–æ–≤.")
        elif confidence > 0.7:
            recommendations.append("‚úÖ –•–æ—Ä–æ—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –ê–≤—Ç–æ–º–æ–±–∏–ª—å –ø—Ä–∏–≥–æ–¥–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ç–∞–∫—Å–∏.")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–Ω–æ—Å—Ç–∏
    if dirt_score > 6:
        recommendations.append("üßº –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ó–ê–ì–†–Ø–ó–ù–ï–ù–ò–ï: –ê–≤—Ç–æ–º–æ–±–∏–ª—å —Å–ª–∏—à–∫–æ–º –≥—Ä—è–∑–Ω—ã–π –¥–ª—è –ø–µ—Ä–µ–≤–æ–∑–∫–∏ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤.")
        recommendations.append("üìâ –ù–∞—Ä—É—à–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –∏–º–∏–¥–∂–∞ —Ç–∞–∫—Å–∏-—Å–µ—Ä–≤–∏—Å–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–π–∫–∞.")
    elif dirt_score > 4:
        recommendations.append("üßΩ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –º–æ–π–∫–∞ –ø–µ—Ä–µ–¥ –≤—ã—Ö–æ–¥–æ–º –Ω–∞ –ª–∏–Ω–∏—é.")
        recommendations.append("üí∞ –ó–∞—Ç—Ä–∞—Ç—ã: 1.5-3 —Ç—ã—Å. —Ä—É–±. –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –º–æ–π–∫—É.")
    elif dirt_score < 2:
        recommendations.append("‚ú® –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–∞—è —á–∏—Å—Ç–æ—Ç–∞! –ê–≤—Ç–æ–º–æ–±–∏–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏.")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ–º–æ–Ω—Ç–æ–ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏
    for msg in repairability_msgs[:2]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2 —Å–æ–æ–±—â–µ–Ω–∏—è
        recommendations.append(msg)
    
    # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
    if confidence < 0.6:
        recommendations.append("‚ùì –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ò–ò-–∞–Ω–∞–ª–∏–∑–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞.")
    
    return recommendations[:6]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 6 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π

@lru_cache(maxsize=1)
def get_model() -> Optional[torch.nn.Module]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ checkpoint —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    p = Path(MODEL_PATH)
    if not p.exists():
        print(f"[inference] MODEL_PATH '{p}' not found")
        return None
    
    device = torch.device(DEVICE)
    model = MulticlassDamageModel(num_classes=3)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
        ckpt = torch.load(str(p), map_location=device, weights_only=False)
        print(f"[inference] Loaded checkpoint type: {type(ckpt)}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç checkpoint –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º state_dict
        state_dict = None
        
        if isinstance(ckpt, dict):
            # –í–∞—Ä–∏–∞–Ω—Ç 1: model_state_dict (—Ñ–æ—Ä–º–∞—Ç –∏–∑ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞)
            if "model_state_dict" in ckpt:
                state_dict = ckpt["model_state_dict"]
                print(f"[inference] Found model_state_dict format")
                if "epoch" in ckpt:
                    print(f"[inference] Model epoch: {ckpt['epoch']}")
                if "f1_score" in ckpt:
                    print(f"[inference] Model F1-score: {ckpt['f1_score']:.4f}")
            
            # –í–∞—Ä–∏–∞–Ω—Ç 2: state_dict
            elif "state_dict" in ckpt:
                state_dict = ckpt["state_dict"]
                print(f"[inference] Found state_dict format")
            
            # –í–∞—Ä–∏–∞–Ω—Ç 3: –ø—Ä—è–º–æ–π state_dict –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–ª—é—á–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
                model_keys = list(model.state_dict().keys())
                if any(key in ckpt for key in model_keys[:3]):  # –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3 –∫–ª—é—á–∞
                    state_dict = ckpt
                    print(f"[inference] Found direct state_dict format")
                else:
                    print(f"[inference] Unknown checkpoint format. Keys: {list(ckpt.keys())}")
                    return None
        else:
            # –í–∞—Ä–∏–∞–Ω—Ç 4: —Å–∞–º checkpoint —è–≤–ª—è–µ—Ç—Å—è state_dict
            state_dict = ckpt
            print(f"[inference] Treating checkpoint as direct state_dict")
        
        if state_dict is None:
            print(f"[inference] Could not extract state_dict from checkpoint")
            return None
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
        
        if missing_keys:
            print(f"[inference] Missing keys: {missing_keys}")
        if unexpected_keys:
            print(f"[inference] Unexpected keys: {unexpected_keys}")
        
        print(f"[inference] Model loaded successfully (missing: {len(missing_keys)}, unexpected: {len(unexpected_keys)})")
        
        model.eval().to(device)
        return model
        
    except Exception as e:
        print(f"[inference] Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return None

def _damage_from_logits(logits: torch.Tensor) -> Dict[str, any]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç logits –º–æ–¥–µ–ª–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è—Ö.
    logits -> softmax(prob_no, prob_minor, prob_major)
    """
    probs = F.softmax(logits, dim=1).detach().cpu().numpy()[0]
    prob_no, prob_minor, prob_major = float(probs[0]), float(probs[1]), float(probs[2])
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞: damaged_prob = 1 - prob_no
    damaged_prob = 1.0 - prob_no
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    class_names = ['no_damage', 'minor_damage', 'major_damage']
    predicted_idx = int(np.argmax(probs))
    predicted_class = class_names[predicted_idx]
    confidence = float(probs[predicted_idx])
    
    return {
        'damaged_prob': round(damaged_prob, 4),
        'damaged': damaged_prob >= 0.5,
        'predicted_class': predicted_class,
        'confidence': round(confidence, 4),
        'probabilities': {
            'no_damage': round(prob_no, 4),
            'minor_damage': round(prob_minor, 4),
            'major_damage': round(prob_major, 4)
        },
        'probs_array': probs
    }

def analyze_image(img_bytes: bytes) -> Dict[str, any]:
    """
    –ì–ª–∞–≤–Ω—ã–π –≤—Ö–æ–¥: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª—è –¥–ª—è —Ñ—Ä–æ–Ω—Ç–∞ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª–∏ –∏ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏.
    """
    img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
    img = ImageOps.exif_transpose(img)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    if not is_vehicle(img):
        return {
            "error": "vehicle_not_detected",
            "message": "‚ö†Ô∏è –ù–∞ —Ñ–æ—Ç–æ, –ø–æ—Ö–æ–∂–µ, –Ω–µ—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—è. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–Ω–∏–º–æ–∫ –º–∞—à–∏–Ω—ã (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ 3/4 —Å–ø–µ—Ä–µ–¥–∏ –∏–ª–∏ —Å–±–æ–∫—É).",
            "dirty": False,
            "dirty_prob": 0.0,
            "damaged": False,
            "damaged_prob": 0.0,
            "model_available": False
        }

    # --- –≥—Ä—è–∑—å ---
    dirt_prob, dirt_metrics, dirt_status, dirt_emoji = analyze_dirt_level(img)

    # --- damage —á–µ—Ä–µ–∑ —Ç–≤–æ—é –º–æ–¥–µ–ª—å ---
    model = get_model()
    if model is None:
        # –µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç ‚Äî –æ—Ç–¥–∞—ë–º —Ç–æ–ª—å–∫–æ –≥—Ä—è–∑—å
        return {
            "dirty": dirt_prob >= 0.5,
            "dirty_prob": round(float(dirt_prob), 4),
            "damaged": False,
            "damaged_prob": 0.0,
            "predicted_class": "unknown",
            "confidence": 0.0,
            "probabilities": {
                "no_damage": 0.0,
                "minor_damage": 0.0,
                "major_damage": 0.0
            },
            "dirt_metrics": dirt_metrics,
            "dirt_status": dirt_status,
            "dirt_emoji": dirt_emoji,
            "model_available": False,
            "expert_recommendations": [
                "‚ö†Ô∏è –ò–ò-–º–æ–¥–µ–ª—å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Å–Ω–æ–≤–∞–Ω —Ç–æ–ª—å–∫–æ –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–Ω–æ—Å—Ç–∏.",
                f"üßº –°–æ—Å—Ç–æ—è–Ω–∏–µ —á–∏—Å—Ç–æ—Ç—ã: {dirt_emoji} {dirt_status}"
            ]
        }

    x = _tf(img).unsqueeze(0).to(DEVICE)
    with torch.inference_mode():
        logits = model(x)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è—Ö
    damage_info = _damage_from_logits(logits)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    expert_recommendations = generate_expert_recommendations(
        damage_info["predicted_class"], 
        damage_info["confidence"], 
        damage_info["probs_array"],
        dirt_status, 
        dirt_metrics["dirt_score"], 
        dirt_metrics
    )

    return {
        "dirty": dirt_prob >= 0.5,
        "dirty_prob": round(float(dirt_prob), 4),
        "damaged": damage_info["damaged"],
        "damaged_prob": damage_info["damaged_prob"],
        "predicted_class": damage_info["predicted_class"],
        "confidence": damage_info["confidence"],
        "probabilities": damage_info["probabilities"],
        "dirt_metrics": dirt_metrics,
        "dirt_status": dirt_status,
        "dirt_emoji": dirt_emoji,
        "model_available": True,
        "expert_recommendations": expert_recommendations
    }

# —É–¥–æ–±–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç
def debug_analyze_image(img_bytes: bytes) -> Dict[str, float]:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è analyze_image —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π.
    """
    result = analyze_image(img_bytes)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    result["debug"] = {
        "model_path": MODEL_PATH,
        "device": DEVICE,
        "model_loaded": result.get("model_available", False)
    }
    
    return result